# jemdoc: menu{MENU}{index.html}
==Han Zhong (钟涵)

~~~
{}{img_left}{photo.jpg}{alt text}{200}{246}
\n \n
Han Zhong \n 
Ph.D. Student \n 
Peking University \n 
Email: hanzhong@stu.pku.edu.cn \n 
[https://scholar.google.com/citations?user=Bk5q_pAAAAAJ&hl=en Google Scholar] / [https://twitter.com/han_zhong1 Twitter] \/ [Wechat.jpeg WeChat]



~~~
 
== About Me 

I am a third-year Ph.D. student at Peking University, where I am fortunate to be advised by Professor [http://www.liweiwang-pku.com Liwei Wang]. Before that, I obtained a bachelor's degree in Mathematics from University of Science and Technology of China (USTC). Additionally, I had the privilege of conducting research at both the Hong Kong University of Science and Technology (HKUST), where I collaborated with Professor [http://tongzhang-ml.org/ Tong Zhang], and at Microsoft Research Asia (MSRA), where I had the opportunity to work with Doctor [https://www.microsoft.com/en-us/research/people/weic/ Wei Chen].

I work on machine learning. The primary goal of my research is to design provably efficient and practical machine learning algorithms, particularly in the context of interactive decision-making problems. To achieve this goal, my recent researches focus on reinforcement learning theory. Currently, I am also interested in [https://aps.arxiv.org/abs/2205.11140 RLHF] (for LLMs) and foundation models (for decision-making problems). If you share common interests and would like to explore collaboration or simply have a discussion, feel free to contact me.


== Selected Publications


+Theoretical Foundation of Interactive Decision Making:+ We propose a unified framework GEC for interactive decision making.

- [https://arxiv.org/abs/2305.18258 One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration] \n 
Zhihan Liu\*, Miao Lu\*, Wei Xiong\*, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023

- [https://arxiv.org/abs/2211.01962 GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond] \n
Han Zhong\*, Wei Xiong\*, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang, Tong Zhang \n
ArXiv preprint \n 



+Multi-Agent Reinforcement Learning:+ We develope the first line of efficient equilibrium-finding algorithms for offline Markov games and Stackelberg Markov games.

- [https://arxiv.org/abs/2112.13521 Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopically Rational Followers?] \n
Han Zhong, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan \n 
Journal of Machine Learning Research (JMLR) 2023 \n

- [https://arxiv.org/abs/2202.07511 Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets] \n
 Han Zhong\*, Wei Xiong\*, Jiyuan Tan\*, Liwei Wang, Tong Zhang, Zhaoran Wang, Zhuoran Yang \n
    International Conference on Machine Learning (ICML) 2022 \n 



+Robust Machine Learning:+ We focus on understanding distributionally robust reinforcement learning and robust generalization in deep learning.

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]  \n 
Jose Blanchet\*, Miao Lu\*, Tong Zhang\*, Han Zhong\* \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 

- [https://arxiv.org/abs/2210.15598 Provable Sim-to-real Transfer in Continuous Domain with Partial Observations] \n 
Jiachen Hu\*, Han Zhong\*, Chi Jin, Liwei Wang \n
International Conference on Learning Representations (ICLR) 2023 \n 

- [https://arxiv.org/abs/2205.13863 Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power] \n
Binghui Li\*, Jikai Jin\*, Han Zhong, John E. Hopcroft, Liwei Wang \n
  Conference on Neural Information Processing Systems (NeurIPS) 2022 \n 


+Policy Optimization:+ We provide theoretical guarantees for policy optimization algorithms, especially optimistic proximal policy optimization (PPO). 

- [https://arxiv.org/abs/2305.08841 A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes] \n
Han Zhong, Tong Zhang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 

- [https://arxiv.org/abs/2112.10935 Nearly Optimal Policy Optimization with Stable at Any Time Guarantee] \n
Tianhao Wu\*, Yunchang Yang\*, Han Zhong\*, Liwei Wang, Simon S. Du, Jiantao Jiao \n
International Conference on Machine Learning (ICML) 2022 

