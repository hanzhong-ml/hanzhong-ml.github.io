# jemdoc: menu{MENU}{index.html}
==Han Zhong (钟涵)

~~~
{}{img_left}{photo.jpg}{alt text}{200}{246}
\n \n
Han Zhong \n 
Ph.D. Student \n 
Peking University \n 
Email: hanzhong@stu.pku.edu.cn \n 
[https://scholar.google.com/citations?user=Bk5q_pAAAAAJ&hl=en Google Scholar]



~~~
 
== About Me 

I am a second year Ph.D. student at Peking University, where I am fortunate to be advised by Professor [http://www.liweiwang-pku.com Liwei Wang]. Before that, I obtained bachelor's degree in Mathematics from University of Science and Technology of China (USTC). Now I am a visiting student at Hong Kong University of Science and Technology (HKUST), working with Professor [http://tongzhang-ml.org/ Tong Zhang]. 


I work on machine learning, especially reinforcement learning theory. If you are interested in collaborating with me or want to have a chat, feel free to contact me through [hanzhong@stu.pku.edu.cn email] or [Wechat.jpeg WeChat].









== Selected Papers

*    * * denotes equal contribution or alphabetical authorship ordering \n
\n



- [https://arxiv.org/abs/2305.08841 A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes] \n
Han Zhong, Tong Zhang \n 
 ArXiv Preprint \n 

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]  \n 
Jose Blanchet\*, Miao Lu\*, Tong Zhang\*, Han Zhong\* \n 
 ArXiv Preprint \n 

- [https://arxiv.org/abs/2302.10796 Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret] \n 
Han Zhong\*, Jiachen Hu\*, Yecheng Xue, Tongyang Li, Liwei Wang \n 
 ArXiv Preprint \n 


- [https://arxiv.org/abs/2211.01962 GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond] \n
Han Zhong\*, Wei Xiong\*, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang, Tong Zhang \n
 ArXiv Preprint \n 

- [https://arxiv.org/abs/2210.15598 Provable Sim-to-real Transfer in Continuous Domain with Partial Observations] \n 
Jiachen Hu\*, Han Zhong\*, Chi Jin, Liwei Wang \n
International Conference on Learning Representations (ICLR) 2023 \n 


- [https://arxiv.org/abs/2112.13521 Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopic Followers?] \n
Han Zhong, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan \n 
Journal of Machine Learning Research (JMLR) 2023 \n


- [https://arxiv.org/abs/2205.13863 Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power] \n
Binghui Li\*, Jikai Jin\*, Han Zhong, John E. Hopcroft, Liwei Wang \n
  Conference on Neural Information Processing Systems (NeurIPS) 2022 \n 


- [https://arxiv.org/abs/2202.07511 Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets] \n
 Han Zhong\*, Wei Xiong\*, Jiyuan Tan\*, Liwei Wang, Tong Zhang, Zhaoran Wang, Zhuoran Yang \n
    International Conference on Machine Learning (ICML) 2022 \n 


- [https://arxiv.org/abs/2112.10935 Nearly Optimal Policy Optimization with Stable at Any Time Guarantee] \n
Tianhao Wu\*, Yunchang Yang\*, Han Zhong\*, Liwei Wang, Simon S. Du, Jiantao Jiao \n
International Conference on Machine Learning (ICML) 2022 