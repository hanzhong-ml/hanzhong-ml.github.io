<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Han Zhong</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p><b>    </b> * denotes equal contribution and α-β order denotes alphabetical authorship ordering <br /></p>
<h2>Conference Publications </h2>
<ul>
<li><p><a href="https://arxiv.org/pdf/2404.18922">DPO Meets PPO: Reinforced Token Optimization for RLHF</a> <br /> 
Han Zhong*, Zikang Shan*, Guhao Feng*, Wei Xiong*, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang <br /> 
International Conference on Machine Learning (ICML) 2025 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2501.18858">BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning</a> <br />
Han Zhong, Yutong Yin, Shenao Zhang, Xiaojun Xu, Yuanxin Liu, Yifei Zuo, Zhihan Liu, Boyi Liu, Sirui Zheng, Hongyi Guo, Liwei Wang, Mingyi Hong, Zhaoran Wang <br /> 
International Conference on Machine Learning (ICML) 2025 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2506.09940">The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability</a> <br /> 
Jiachen Hu, Rui Ai, Han Zhong, Xiaoyu Chen, Liwei Wang, Zhaoran Wang, Zhuoran Yang <br /> 
International Conference on Machine Learning (ICML) 2025 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2312.17248">Rethinking Model-based, Policy-based, and Value-based Reinforcement Learning via the Lens of Representation Complexity</a> <br /> 
(α-β order) Guhao Feng, Han Zhong <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2404.03578">Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithm</a> <br /> 
Miao Lu*, Han Zhong*, Tong Zhang, Jose Blanchet <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2302.10796">Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret</a> <br /> 
Han Zhong*, Jiachen Hu*, Yecheng Xue, Tongyang Li, Liwei Wang <br /> 
International Conference on Machine Learning (ICML) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2312.11456">Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint</a> <br /> 
Wei Xiong*, Hanze Dong*, Chenlu Ye*, Ziqi Wang, Han Zhong, Heng Ji, Nan Jiang, Tong Zhang <br />
International Conference on Machine Learning (ICML) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2402.10207">Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment</a> <br />
Rui Yang*, Xiaoman Pan*, Feng Luo*, Shuang Qiu*, Han Zhong, Dong Yu, Jianshu Chen <br /> 
International Conference on Machine Learning (ICML) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2406.01386">Combinatorial Multivariant Multi-Armed Bandits with Applications to Episodic Reinforcement Learning and Beyond</a> <br /> 
Xutong Liu, Siwei Wang, Jinhang Zuo, Han Zhong, Xuchuang Wang, Zhiyong Wang, Shuai Li, Mohammad Hajiesmaili, John C.S. Lui, Wei Chen <br /> 
International Conference on Machine Learning (ICML) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2407.10196">A3S: A General Active Clustering Method with Pairwise Constraints</a> <br /> 
Xun Deng, Junlong Liu, Han Zhong, Fuli Feng, Chen Shen, Xiangnan He, Jieping Ye, Zheng Wang <br /> 
International Conference on Machine Learning (ICML) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2310.12955">Towards Robust Offline Reinforcement Learning under Diverse Data Corruption</a> <br /> 
Rui Yang*, Han Zhong*, Jiawei Xu*, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang <br /> 
International Conference on Learning Representations (ICLR) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2404.12648">Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation</a> <br /> 
Jianliang He, Han Zhong, Zhuoran Yang <br /> 
International Conference on Learning Representations (ICLR) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2312.04464">Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation</a> <br /> 
Jiayi Huang, Han Zhong, Liwei Wang, Lin F. Yang <br /> 
International Conference on Artificial Intelligence and Statistics (AISTATS) 2024 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2305.08841">A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes</a> <br />
Han Zhong, Tong Zhang <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2305.09659">Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage</a>  <br /> 
(α-β order) Jose Blanchet, Miao Lu, Tong Zhang, Han Zhong  <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2023 (short version) <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2305.18258">Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration</a> <br /> 
Zhihan Liu*, Miao Lu*, Wei Xiong*, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2306.06836">Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds</a> <br /> 
Jiayi Huang, Han Zhong, Liwei Wang, Lin F. Yang <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2302.01477">A Reduction-based Framework for Sequential Decision Making with Delayed Feedback</a> <br />
Yunchang Yang*, Han Zhong*, Tianhao Wu*, Bin Liu, Liwei Wang, Simon S. Du <br />
Conference on Neural Information Processing Systems (NeurIPS) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2310.19861">Posterior Sampling for Competitive RL: Function Approximation and Partial Observation</a> <br /> 
Shuang Qiu*, Ziyu Dai*, Han Zhong, Zhaoran Wang, Zhuoran Yang, Tong Zhang <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2210.15598">Provable Sim-to-real Transfer in Continuous Domain with Partial Observations</a> <br /> 
Jiachen Hu*, Han Zhong*, Chi Jin, Liwei Wang <br />
International Conference on Learning Representations (ICLR) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2205.15512">Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game</a> <br />
Wei Xiong*, Han Zhong*, Chengshuai Shi, Cong Shen, Liwei Wang, Tong Zhang <br />
International Conference on Learning Representations (ICLR) 2023 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2205.13863">Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power</a> <br />
Binghui Li*, Jikai Jin*, Han Zhong, John E. Hopcroft, Liwei Wang <br />
Conference on Neural Information Processing Systems (NeurIPS) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2202.07511">Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets</a> <br />
Han Zhong*, Wei Xiong*, Jiyuan Tan*, Liwei Wang, Tong Zhang, Zhaoran Wang, Zhuoran Yang <br />
International Conference on Machine Learning (ICML) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2112.10935">Nearly Optimal Policy Optimization with Stable at Any Time Guarantee</a> <br />
Tianhao Wu*, Yunchang Yang*, Han Zhong*, Liwei Wang, Simon S. Du, Jiantao Jiao <br />
International Conference on Machine Learning (ICML) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2205.11140">Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation</a> <br /> 
Xiaoyu Chen*, Han Zhong*, Zhuoran Yang, Zhaoran Wang, Liwei Wang <br />
International Conference on Machine Learning (ICML) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2210.01907">A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games</a> <br /> 
Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Tong Zhang <br />
International Conference on Machine Learning (ICML) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2106.11692">A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning</a> <br />
Yunchang Yang*, Tianhao Wu*, Han Zhong*, Evrard Garcelon, Matteo Pirotta, Alessandro Lazaric, Liwei Wang, Simon S. Du <br /> 
International Conference on Learning Representations (ICLR) 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2110.13876">Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits with Super Heavy-Tailed Payoffs</a> <br />
Han Zhong, Jiayi Huang, Lin F. Yang, Liwei Wang <br /> 
Conference on Neural Information Processing Systems (NeurIPS) 2021 </p>
</li>
</ul>
<h2>Journal Publications </h2>
<ul>
<li><p><a href="https://arxiv.org/pdf/2211.01962">GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond</a> <br />
Han Zhong*, Wei Xiong*, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang, Tong Zhang <br />
Mathematics of Operations Research (MOR), 2025+ <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2405.19332">Self-Exploring Language Models: Active Preference Elicitation for Online Alignment</a> <br /> 
Shenao Zhang, Donghan Yu, Hiteshi Sharma, Han Zhong, Zhihan Liu, Ziyi Yang, Shuohang Wang, Hany Hassan, Zhaoran Wang <br /> 
Transactions on Machine Learning Research (TMLR) 2025 <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://www.jmlr.org/papers/volume24/22-0203/22-0203.pdf">Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopically Rational Followers?</a> <br />
Han Zhong, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan <br /> 
Journal of Machine Learning Research (JMLR) 2023 <br /></p>
</li>
</ul>
<h2>Preprints</h2>
<ul>
<li><p><a href="https://arxiv.org/pdf/2502.06777">Learning an Optimal Assortment Policy under Observational Data</a> <br /> 
Yuxuan Han, Han Zhong, Miao Lu, Jose Blanchet, Zhengyuan Zhou <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2502.14560">Less is More: Improving LLM Alignment via Preference Data Selection</a> <br /> 
Xun Deng, Han Zhong, Rui Ai, Fuli Feng, Zheng Wang, Xiangnan He <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2110.08984">Optimistic Policy Optimization is Provably Efficient in Non-stationary MDPs</a> <br /> 
Han Zhong, Zhongren Chen, Zhuoran Yang, Zhaoran Wang, Csaba Szepesvári <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2012.14098">Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy</a> <br /> 
Han Zhong, Xun Deng, Ethan X. Fang, Zhuoran Yang, Zhaoran Wang, Runze Li  </p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-12 15:03:25 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
