# jemdoc: menu{MENU}{publications.html}
== Publications

*    * * denotes equal contribution \n


== Conference Publications 

- [https://arxiv.org/abs/2305.08841 A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes] \n
Han Zhong, Tong Zhang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]  \n 
Jose Blanchet, Miao Lu, Tong Zhang, Han Zhong (alphabetical order) \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 (short version) \n 


- [https://arxiv.org/abs/2305.18258 Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration] \n 
Zhihan Liu\*, Miao Lu\*, Wei Xiong\*, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 


- [https://arxiv.org/abs/2306.06836 Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds] \n 
Jiayi Huang, Han Zhong, Liwei Wang, Lin F. Yang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 


- [https://arxiv.org/abs/2302.01477 A Reduction-based Framework for Sequential Decision Making with Delayed Feedback] \n
Yunchang Yang\*, Han Zhong\*, Tianhao Wu\*, Bin Liu, Liwei Wang, Simon S. Du \n
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 

- [https://arxiv.org/abs/2310.19861 Posterior Sampling for Competitive RL: Function Approximation and Partial Observation] \n 
Shuang Qiu\*, Ziyu Dai\*, Han Zhong, Zhaoran Wang, Zhuoran Yang, Tong Zhang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2023 \n 

- [https://arxiv.org/abs/2210.15598 Provable Sim-to-real Transfer in Continuous Domain with Partial Observations] \n 
Jiachen Hu\*, Han Zhong\*, Chi Jin, Liwei Wang \n
International Conference on Learning Representations (ICLR) 2023 \n 


- [https://arxiv.org/abs/2205.15512 Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game] \n
Wei Xiong\*, Han Zhong\*, Chengshuai Shi, Cong Shen, Liwei Wang, Tong Zhang \n
 International Conference on Learning Representations (ICLR) 2023 \n 


- [https://arxiv.org/abs/2205.13863 Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power] \n
Binghui Li\*, Jikai Jin\*, Han Zhong, John E. Hopcroft, Liwei Wang \n
  Conference on Neural Information Processing Systems (NeurIPS) 2022 \n 


- [https://arxiv.org/abs/2202.07511 Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets] \n
 Han Zhong\*, Wei Xiong\*, Jiyuan Tan\*, Liwei Wang, Tong Zhang, Zhaoran Wang, Zhuoran Yang \n
    International Conference on Machine Learning (ICML) 2022 \n 
     ICLR 2022 Workshop on Gamification and Multiagent Solutions \n


- [https://arxiv.org/abs/2210.01907  A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games] \n 
Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Tong Zhang \n
 International Conference on Machine Learning (ICML) 2022 \n 
     ICLR 2022 Workshop on Gamification and Multiagent Solutions \n

- [https://arxiv.org/abs/2112.10935 Nearly Optimal Policy Optimization with Stable at Any Time Guarantee] \n
Tianhao Wu\*, Yunchang Yang\*, Han Zhong\*, Liwei Wang, Simon S. Du, Jiantao Jiao \n
International Conference on Machine Learning (ICML) 2022 \n 

- [https://aps.arxiv.org/abs/2205.11140 Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation] \n 
Xiaoyu Chen\*, Han Zhong\*, Zhuoran Yang, Zhaoran Wang, Liwei Wang \n
International Conference on Machine Learning (ICML) 2022 \n 
  

- [https://arxiv.org/abs/2106.11692 A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning] \n
Yunchang Yang\*, Tianhao Wu\*, Han Zhong\*, Evrard Garcelon, Matteo Pirotta, Alessandro Lazaric, Liwei Wang, Simon S. Du \n 
International Conference on Learning Representations (ICLR) 2022 \n 


- [https://arxiv.org/abs/2110.13876 Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits with Super Heavy-Tailed Payoffs] \n
Han Zhong, Jiayi Huang, Lin F. Yang, Liwei Wang \n 
 Conference on Neural Information Processing Systems (NeurIPS) 2021 

== Journal Publications 

- [https://arxiv.org/abs/2112.13521 Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopically Rational Followers?] \n
Han Zhong, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan \n 
Journal of Machine Learning Research (JMLR) 2023 \n
ICLR 2022 Workshop on Gamification and Multiagent Solutions 

 == Preprints

- [https://arxiv.org/abs/2312.17248 Rethinking Model-based, Policy-based, and Value-based Reinforcement Learning via the Lens of Representation Complexity] \n 
Guhao Feng, Han Zhong (alphabetical order) \n 

- [https://arxiv.org/abs/2312.11456 Gibbs Sampling from Human Feedback: A Provable KL-constrained Framework for RLHF] \n 
Wei Xiong\*, Hanze Dong\*, Chenlu Ye\*, Han Zhong, Nan Jiang, Tong Zhang \n


- [https://arxiv.org/abs/2310.12955 Towards Robust Offline Reinforcement Learning under Diverse Data Corruption] \n 
Rui Yang\*, Han Zhong\*, Jiawei Xu\*, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang \n 

- [https://arxiv.org/abs/2302.10796 Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret] \n 
Han Zhong\*, Jiachen Hu\*, Yecheng Xue, Tongyang Li, Liwei Wang \n 


- [https://arxiv.org/abs/2211.01962 GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond] \n
Han Zhong\*, Wei Xiong\*, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang, Tong Zhang \n

 - [https://arxiv.org/abs/2110.08984 Optimistic Policy Optimization is Provably Efficient in Non-stationary MDPs] \n 
Han Zhong, Zhuoran Yang, Zhaoran Wang, Csaba Szepesv√°ri \n 

- [https://arxiv.org/abs/2012.14098 Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy] \n 
Han Zhong, Xun Deng, Ethan X. Fang, Zhuoran Yang, Zhaoran Wang, Runze Li  
